Visual geo-localization (VG) is the task of coarsely finding the geographical position where a given photograph was taken. This task is commonly addressed as an image retrieval problem: given an unseen image to be localized (query), it is matched against a database of geo-tagged images that represent the known world. The N-top retrieved images, with their geo-tag (typically GPS coordinates), provide the hypothesis for the query's geographical location.
In this project you will work with an innovative approach that was recently published and that casts the problem as Classification, at training time. For inference, the extracted features are used for retrieval as usual.
The retrieval is performed as a k Nearest Neighbour search in a learned embedding space that well represents the visual similarity of places. Namely, each image is passed through a network composed of a feature extraction backbone and a head that aggregates or pools the features to create a global descriptor of the image. 
In earlier work the training was performed using a contrastive learning approach. The model learns to extract descriptors that are discriminative of locations. The similarity search is then implemented as a pairwise comparison among descriptors, e.g. using a cosine similarity. In the new presented approach, at train time the network divides the geographical area to classify into squares, distinguishing inside each square the heading (e.g. spatial orientation), and is trained to classify the location of the images.
In this project, you will become familiar with the task of visual geo-localization and with how a visual geo-localization system works. You will start by experimenting with the baselines using a codebase provided by us.Subsequently you will focus on improving one or more aspects of the system of your choice, from robustness to illumination changes (e.g. pictures taken at night), different perspectives and occlusions.  We already provide you with the code to implement the baseline, so that you do not have to waste time in re-implementing them; in this way you can focus on 

